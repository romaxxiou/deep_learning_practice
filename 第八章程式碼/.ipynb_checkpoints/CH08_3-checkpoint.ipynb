{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape :  (768, 8)\n",
      "label.shape :  (768,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# 加載，預處理數據集\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "data = dataset[:, 0:8]    # 資料集\n",
    "label = dataset[:, 8]     # 標籤\n",
    "\n",
    "print(\"data.shape : \", data.shape)   # 印出資料集的維度\n",
    "print(\"label.shape : \",label.shape)  # 印出標籤維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())  # 印出網路資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 - 4s - loss: 10.3030 - accuracy: 0.3453 - val_loss: 5.3371 - val_accuracy: 0.4416\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 2.6840 - accuracy: 0.4837 - val_loss: 1.2151 - val_accuracy: 0.6234\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 1.2240 - accuracy: 0.6091 - val_loss: 1.0901 - val_accuracy: 0.6039\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 1.0736 - accuracy: 0.6059 - val_loss: 0.9191 - val_accuracy: 0.5974\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.9121 - accuracy: 0.6466 - val_loss: 0.7942 - val_accuracy: 0.6234\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.8096 - accuracy: 0.6433 - val_loss: 0.7036 - val_accuracy: 0.6364\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.7417 - accuracy: 0.6596 - val_loss: 0.7166 - val_accuracy: 0.6169\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.7265 - accuracy: 0.6466 - val_loss: 0.6756 - val_accuracy: 0.6364\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.7007 - accuracy: 0.6596 - val_loss: 0.6721 - val_accuracy: 0.6364\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.6897 - accuracy: 0.6466 - val_loss: 0.6699 - val_accuracy: 0.6429\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.6763 - accuracy: 0.6564 - val_loss: 0.6897 - val_accuracy: 0.5584\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.6682 - accuracy: 0.6678 - val_loss: 0.6593 - val_accuracy: 0.6364\n",
      "Epoch 13/100\n",
      "62/62 - 0s - loss: 0.6732 - accuracy: 0.6482 - val_loss: 0.6749 - val_accuracy: 0.6104\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.6439 - accuracy: 0.6759 - val_loss: 0.6546 - val_accuracy: 0.6494\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.6333 - accuracy: 0.6792 - val_loss: 0.6551 - val_accuracy: 0.6429\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.6211 - accuracy: 0.6808 - val_loss: 0.6643 - val_accuracy: 0.6364\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.6129 - accuracy: 0.6954 - val_loss: 0.6635 - val_accuracy: 0.6364\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.6151 - accuracy: 0.6840 - val_loss: 0.6499 - val_accuracy: 0.6558\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.6117 - accuracy: 0.6889 - val_loss: 0.6429 - val_accuracy: 0.6818\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.6159 - accuracy: 0.6792 - val_loss: 0.6488 - val_accuracy: 0.6558\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.6038 - accuracy: 0.6938 - val_loss: 0.6404 - val_accuracy: 0.6948\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.6077 - accuracy: 0.6743 - val_loss: 0.6443 - val_accuracy: 0.6688\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.6000 - accuracy: 0.6906 - val_loss: 0.6470 - val_accuracy: 0.6364\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.5928 - accuracy: 0.6873 - val_loss: 0.6748 - val_accuracy: 0.6104\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.5980 - accuracy: 0.6889 - val_loss: 0.6364 - val_accuracy: 0.6623\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.5954 - accuracy: 0.6954 - val_loss: 0.6456 - val_accuracy: 0.6364\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.5960 - accuracy: 0.6922 - val_loss: 0.6405 - val_accuracy: 0.6558\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.5916 - accuracy: 0.6938 - val_loss: 0.6381 - val_accuracy: 0.6623\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.5899 - accuracy: 0.7068 - val_loss: 0.6422 - val_accuracy: 0.6494\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.6052 - accuracy: 0.6954 - val_loss: 0.6440 - val_accuracy: 0.6234\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.5876 - accuracy: 0.7003 - val_loss: 0.6357 - val_accuracy: 0.6494\n",
      "Epoch 32/100\n",
      "62/62 - 0s - loss: 0.5964 - accuracy: 0.7134 - val_loss: 0.6422 - val_accuracy: 0.6364\n",
      "Epoch 33/100\n",
      "62/62 - 0s - loss: 0.5881 - accuracy: 0.6987 - val_loss: 0.6281 - val_accuracy: 0.6818\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.5914 - accuracy: 0.7150 - val_loss: 0.6302 - val_accuracy: 0.6494\n",
      "Epoch 35/100\n",
      "62/62 - 0s - loss: 0.5889 - accuracy: 0.7036 - val_loss: 0.6205 - val_accuracy: 0.6753\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.5838 - accuracy: 0.7231 - val_loss: 0.6245 - val_accuracy: 0.6688\n",
      "Epoch 37/100\n",
      "62/62 - 0s - loss: 0.5801 - accuracy: 0.7166 - val_loss: 0.6230 - val_accuracy: 0.6818\n",
      "Epoch 38/100\n",
      "62/62 - 0s - loss: 0.5851 - accuracy: 0.6938 - val_loss: 0.6271 - val_accuracy: 0.6429\n",
      "Epoch 39/100\n",
      "62/62 - 0s - loss: 0.5790 - accuracy: 0.7117 - val_loss: 0.6345 - val_accuracy: 0.6429\n",
      "Epoch 40/100\n",
      "62/62 - 0s - loss: 0.5753 - accuracy: 0.7166 - val_loss: 0.6308 - val_accuracy: 0.6494\n",
      "Epoch 41/100\n",
      "62/62 - 0s - loss: 0.5740 - accuracy: 0.7166 - val_loss: 0.6199 - val_accuracy: 0.6688\n",
      "Epoch 42/100\n",
      "62/62 - 0s - loss: 0.5774 - accuracy: 0.7036 - val_loss: 0.6267 - val_accuracy: 0.6688\n",
      "Epoch 43/100\n",
      "62/62 - 0s - loss: 0.5791 - accuracy: 0.7182 - val_loss: 0.6284 - val_accuracy: 0.6558\n",
      "Epoch 44/100\n",
      "62/62 - 0s - loss: 0.5799 - accuracy: 0.7134 - val_loss: 0.6532 - val_accuracy: 0.6364\n",
      "Epoch 45/100\n",
      "62/62 - 0s - loss: 0.5775 - accuracy: 0.7117 - val_loss: 0.6146 - val_accuracy: 0.6558\n",
      "Epoch 46/100\n",
      "62/62 - 0s - loss: 0.5763 - accuracy: 0.7199 - val_loss: 0.6223 - val_accuracy: 0.6494\n",
      "Epoch 47/100\n",
      "62/62 - 0s - loss: 0.5718 - accuracy: 0.7231 - val_loss: 0.6222 - val_accuracy: 0.6429\n",
      "Epoch 48/100\n",
      "62/62 - 0s - loss: 0.5696 - accuracy: 0.7280 - val_loss: 0.6190 - val_accuracy: 0.6494\n",
      "Epoch 49/100\n",
      "62/62 - 0s - loss: 0.5734 - accuracy: 0.7052 - val_loss: 0.6250 - val_accuracy: 0.6494\n",
      "Epoch 50/100\n",
      "62/62 - 0s - loss: 0.5769 - accuracy: 0.7150 - val_loss: 0.6127 - val_accuracy: 0.6494\n",
      "Epoch 51/100\n",
      "62/62 - 0s - loss: 0.5721 - accuracy: 0.7036 - val_loss: 0.6334 - val_accuracy: 0.6429\n",
      "Epoch 52/100\n",
      "62/62 - 0s - loss: 0.5687 - accuracy: 0.7329 - val_loss: 0.6236 - val_accuracy: 0.6429\n",
      "Epoch 53/100\n",
      "62/62 - 0s - loss: 0.5694 - accuracy: 0.7199 - val_loss: 0.6109 - val_accuracy: 0.6688\n",
      "Epoch 54/100\n",
      "62/62 - 0s - loss: 0.5645 - accuracy: 0.7248 - val_loss: 0.6068 - val_accuracy: 0.6494\n",
      "Epoch 55/100\n",
      "62/62 - 0s - loss: 0.5708 - accuracy: 0.7231 - val_loss: 0.6114 - val_accuracy: 0.6753\n",
      "Epoch 56/100\n",
      "62/62 - 0s - loss: 0.5601 - accuracy: 0.7296 - val_loss: 0.6161 - val_accuracy: 0.6558\n",
      "Epoch 57/100\n",
      "62/62 - 0s - loss: 0.5722 - accuracy: 0.7101 - val_loss: 0.6133 - val_accuracy: 0.6558\n",
      "Epoch 58/100\n",
      "62/62 - 0s - loss: 0.5576 - accuracy: 0.7459 - val_loss: 0.6132 - val_accuracy: 0.6623\n",
      "Epoch 59/100\n",
      "62/62 - 0s - loss: 0.5559 - accuracy: 0.7345 - val_loss: 0.6126 - val_accuracy: 0.6753\n",
      "Epoch 60/100\n",
      "62/62 - 0s - loss: 0.5529 - accuracy: 0.7378 - val_loss: 0.6108 - val_accuracy: 0.6494\n",
      "Epoch 61/100\n",
      "62/62 - 0s - loss: 0.5616 - accuracy: 0.7182 - val_loss: 0.6077 - val_accuracy: 0.6818\n",
      "Epoch 62/100\n",
      "62/62 - 0s - loss: 0.5634 - accuracy: 0.7199 - val_loss: 0.6138 - val_accuracy: 0.6688\n",
      "Epoch 63/100\n",
      "62/62 - 0s - loss: 0.5597 - accuracy: 0.7134 - val_loss: 0.6136 - val_accuracy: 0.6494\n",
      "Epoch 64/100\n",
      "62/62 - 0s - loss: 0.5578 - accuracy: 0.7313 - val_loss: 0.6119 - val_accuracy: 0.6688\n",
      "Epoch 65/100\n",
      "62/62 - 0s - loss: 0.5553 - accuracy: 0.7264 - val_loss: 0.6122 - val_accuracy: 0.6558\n",
      "Epoch 66/100\n",
      "62/62 - 0s - loss: 0.5538 - accuracy: 0.7248 - val_loss: 0.6071 - val_accuracy: 0.6623\n",
      "Epoch 67/100\n",
      "62/62 - 0s - loss: 0.5497 - accuracy: 0.7362 - val_loss: 0.6034 - val_accuracy: 0.6753\n",
      "Epoch 68/100\n",
      "62/62 - 0s - loss: 0.5535 - accuracy: 0.7280 - val_loss: 0.6028 - val_accuracy: 0.6948\n",
      "Epoch 69/100\n",
      "62/62 - 0s - loss: 0.5572 - accuracy: 0.7378 - val_loss: 0.6151 - val_accuracy: 0.6494\n",
      "Epoch 70/100\n",
      "62/62 - 0s - loss: 0.5513 - accuracy: 0.7427 - val_loss: 0.6090 - val_accuracy: 0.6558\n",
      "Epoch 71/100\n",
      "62/62 - 0s - loss: 0.5483 - accuracy: 0.7378 - val_loss: 0.6122 - val_accuracy: 0.6623\n",
      "Epoch 72/100\n",
      "62/62 - 0s - loss: 0.5442 - accuracy: 0.7427 - val_loss: 0.6131 - val_accuracy: 0.6494\n",
      "Epoch 73/100\n",
      "62/62 - 0s - loss: 0.5506 - accuracy: 0.7280 - val_loss: 0.5996 - val_accuracy: 0.6558\n",
      "Epoch 74/100\n",
      "62/62 - 0s - loss: 0.5467 - accuracy: 0.7362 - val_loss: 0.6072 - val_accuracy: 0.6688\n",
      "Epoch 75/100\n",
      "62/62 - 0s - loss: 0.5498 - accuracy: 0.7199 - val_loss: 0.6313 - val_accuracy: 0.6494\n",
      "Epoch 76/100\n",
      "62/62 - 0s - loss: 0.5488 - accuracy: 0.7410 - val_loss: 0.5942 - val_accuracy: 0.6883\n",
      "Epoch 77/100\n",
      "62/62 - 0s - loss: 0.5424 - accuracy: 0.7280 - val_loss: 0.5943 - val_accuracy: 0.6883\n",
      "Epoch 78/100\n",
      "62/62 - 0s - loss: 0.5466 - accuracy: 0.7443 - val_loss: 0.5979 - val_accuracy: 0.6818\n",
      "Epoch 79/100\n",
      "62/62 - 0s - loss: 0.5492 - accuracy: 0.7459 - val_loss: 0.5962 - val_accuracy: 0.6623\n",
      "Epoch 80/100\n",
      "62/62 - 0s - loss: 0.5471 - accuracy: 0.7362 - val_loss: 0.6069 - val_accuracy: 0.6623\n",
      "Epoch 81/100\n",
      "62/62 - 0s - loss: 0.5348 - accuracy: 0.7557 - val_loss: 0.6097 - val_accuracy: 0.6948\n",
      "Epoch 82/100\n",
      "62/62 - 0s - loss: 0.5455 - accuracy: 0.7362 - val_loss: 0.5912 - val_accuracy: 0.7078\n",
      "Epoch 83/100\n",
      "62/62 - 0s - loss: 0.5432 - accuracy: 0.7296 - val_loss: 0.5906 - val_accuracy: 0.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "62/62 - 0s - loss: 0.5367 - accuracy: 0.7329 - val_loss: 0.5986 - val_accuracy: 0.7013\n",
      "Epoch 85/100\n",
      "62/62 - 0s - loss: 0.5515 - accuracy: 0.7508 - val_loss: 0.5885 - val_accuracy: 0.6688\n",
      "Epoch 86/100\n",
      "62/62 - 0s - loss: 0.5388 - accuracy: 0.7476 - val_loss: 0.5945 - val_accuracy: 0.6753\n",
      "Epoch 87/100\n",
      "62/62 - 0s - loss: 0.5324 - accuracy: 0.7508 - val_loss: 0.5975 - val_accuracy: 0.6818\n",
      "Epoch 88/100\n",
      "62/62 - 0s - loss: 0.5403 - accuracy: 0.7231 - val_loss: 0.5882 - val_accuracy: 0.6818\n",
      "Epoch 89/100\n",
      "62/62 - 0s - loss: 0.5307 - accuracy: 0.7345 - val_loss: 0.5790 - val_accuracy: 0.7013\n",
      "Epoch 90/100\n",
      "62/62 - 0s - loss: 0.5343 - accuracy: 0.7524 - val_loss: 0.5973 - val_accuracy: 0.6753\n",
      "Epoch 91/100\n",
      "62/62 - 0s - loss: 0.5310 - accuracy: 0.7459 - val_loss: 0.5926 - val_accuracy: 0.7078\n",
      "Epoch 92/100\n",
      "62/62 - 0s - loss: 0.5353 - accuracy: 0.7345 - val_loss: 0.5866 - val_accuracy: 0.7078\n",
      "Epoch 93/100\n",
      "62/62 - 0s - loss: 0.5305 - accuracy: 0.7492 - val_loss: 0.5909 - val_accuracy: 0.6948\n",
      "Epoch 94/100\n",
      "62/62 - 0s - loss: 0.5357 - accuracy: 0.7394 - val_loss: 0.5958 - val_accuracy: 0.6883\n",
      "Epoch 95/100\n",
      "62/62 - 0s - loss: 0.5294 - accuracy: 0.7345 - val_loss: 0.6005 - val_accuracy: 0.6558\n",
      "Epoch 96/100\n",
      "62/62 - 0s - loss: 0.5290 - accuracy: 0.7459 - val_loss: 0.5796 - val_accuracy: 0.7013\n",
      "Epoch 97/100\n",
      "62/62 - 0s - loss: 0.5232 - accuracy: 0.7557 - val_loss: 0.5809 - val_accuracy: 0.7013\n",
      "Epoch 98/100\n",
      "62/62 - 0s - loss: 0.5354 - accuracy: 0.7264 - val_loss: 0.5911 - val_accuracy: 0.7013\n",
      "Epoch 99/100\n",
      "62/62 - 0s - loss: 0.5267 - accuracy: 0.7427 - val_loss: 0.5823 - val_accuracy: 0.7078\n",
      "Epoch 100/100\n",
      "62/62 - 0s - loss: 0.5257 - accuracy: 0.7524 - val_loss: 0.5833 - val_accuracy: 0.6948\n",
      "history:  {'loss': [10.302963256835938, 2.683966875076294, 1.2239645719528198, 1.0735589265823364, 0.9121453762054443, 0.8096330761909485, 0.7417322397232056, 0.7264972925186157, 0.7007328271865845, 0.6897191405296326, 0.6762712001800537, 0.6682493090629578, 0.6732493042945862, 0.6438572406768799, 0.6333323121070862, 0.6211268305778503, 0.6129245758056641, 0.6150553822517395, 0.6116812229156494, 0.6158990859985352, 0.6037827134132385, 0.6076797842979431, 0.5999516844749451, 0.5927957892417908, 0.5979810953140259, 0.5954089760780334, 0.5959504246711731, 0.5916157960891724, 0.58991539478302, 0.6051689386367798, 0.5875740647315979, 0.5963525176048279, 0.588095486164093, 0.5914238095283508, 0.5888906717300415, 0.5837962627410889, 0.5800548791885376, 0.5851026177406311, 0.5789598822593689, 0.5752811431884766, 0.57398921251297, 0.577398419380188, 0.579058051109314, 0.5799283981323242, 0.5774632096290588, 0.5763404965400696, 0.5718236565589905, 0.5696444511413574, 0.5734478831291199, 0.5769180655479431, 0.5720533132553101, 0.5687490701675415, 0.5694339275360107, 0.5644652247428894, 0.5707578659057617, 0.5600829720497131, 0.572234034538269, 0.5575529336929321, 0.55586838722229, 0.5529285073280334, 0.5616487860679626, 0.5634430050849915, 0.5596795678138733, 0.5577536821365356, 0.5553241968154907, 0.5538227558135986, 0.5496917963027954, 0.553470253944397, 0.5572145581245422, 0.551270067691803, 0.5482903718948364, 0.544233500957489, 0.5505756735801697, 0.5467029809951782, 0.5498489737510681, 0.5488375425338745, 0.5424196124076843, 0.5465572476387024, 0.5492197871208191, 0.5471025109291077, 0.5348066687583923, 0.5454676151275635, 0.5432047843933105, 0.5367392897605896, 0.5515416264533997, 0.5387759804725647, 0.5323925614356995, 0.5402579307556152, 0.5306985378265381, 0.5342960357666016, 0.5310207009315491, 0.5353185534477234, 0.5305006504058838, 0.535713791847229, 0.529440701007843, 0.5290488004684448, 0.5232411623001099, 0.5354292988777161, 0.5266703963279724, 0.5257431864738464], 'accuracy': [0.3452768623828888, 0.4837133586406708, 0.6091205477714539, 0.6058632135391235, 0.6465798020362854, 0.6433224678039551, 0.6596091389656067, 0.6465798020362854, 0.6596091389656067, 0.6465798020362854, 0.6563518047332764, 0.6677524447441101, 0.6482084393501282, 0.6758957505226135, 0.6791530847549438, 0.6807817816734314, 0.6954397559165955, 0.6840391159057617, 0.6889250874519348, 0.6791530847549438, 0.6938110589981079, 0.6742671132087708, 0.6905537247657776, 0.6872963905334473, 0.6889250874519348, 0.6954397559165955, 0.6921824216842651, 0.6938110589981079, 0.7068403959274292, 0.6954397559165955, 0.7003257274627686, 0.7133550643920898, 0.6986970901489258, 0.7149837017059326, 0.7035830616950989, 0.723127007484436, 0.7166123986244202, 0.6938110589981079, 0.7117263674736023, 0.7166123986244202, 0.7166123986244202, 0.7035830616950989, 0.7182410359382629, 0.7133550643920898, 0.7117263674736023, 0.7198697328567505, 0.723127007484436, 0.7280130386352539, 0.7052116990089417, 0.7149837017059326, 0.7035830616950989, 0.732899010181427, 0.7198697328567505, 0.7247557044029236, 0.723127007484436, 0.7296416759490967, 0.7100977301597595, 0.7459283471107483, 0.7345277070999146, 0.7377850413322449, 0.7182410359382629, 0.7198697328567505, 0.7133550643920898, 0.7312703728675842, 0.7263843417167664, 0.7247557044029236, 0.7361563444137573, 0.7280130386352539, 0.7377850413322449, 0.742671012878418, 0.7377850413322449, 0.742671012878418, 0.7280130386352539, 0.7361563444137573, 0.7198697328567505, 0.7410423159599304, 0.7280130386352539, 0.7442996501922607, 0.7459283471107483, 0.7361563444137573, 0.7557003498077393, 0.7361563444137573, 0.7296416759490967, 0.732899010181427, 0.7508143186569214, 0.7475569844245911, 0.7508143186569214, 0.723127007484436, 0.7345277070999146, 0.7524430155754089, 0.7459283471107483, 0.7345277070999146, 0.7491856813430786, 0.7394136786460876, 0.7345277070999146, 0.7459283471107483, 0.7557003498077393, 0.7263843417167664, 0.742671012878418, 0.7524430155754089], 'val_loss': [5.337078094482422, 1.2150557041168213, 1.090110421180725, 0.9191420078277588, 0.7942025065422058, 0.7035589218139648, 0.7166005373001099, 0.67564457654953, 0.6721225380897522, 0.669867217540741, 0.6897053122520447, 0.6593449115753174, 0.6749216914176941, 0.6546309590339661, 0.655062198638916, 0.6642799973487854, 0.6635412573814392, 0.6498591303825378, 0.6428738832473755, 0.6488096117973328, 0.6403794884681702, 0.6443225145339966, 0.6469816565513611, 0.6748031973838806, 0.6363528966903687, 0.6456212401390076, 0.6405074596405029, 0.6380815505981445, 0.6422415375709534, 0.6440389752388, 0.635657787322998, 0.6422203183174133, 0.6280827522277832, 0.6301895976066589, 0.6205187439918518, 0.6245395541191101, 0.6230432391166687, 0.6271069049835205, 0.6345489025115967, 0.6307658553123474, 0.6198675632476807, 0.6266955137252808, 0.6283800005912781, 0.6532109379768372, 0.6145652532577515, 0.6223178505897522, 0.6222147345542908, 0.6190425157546997, 0.624968945980072, 0.6127267479896545, 0.6334401369094849, 0.6236473917961121, 0.6109274625778198, 0.6068192720413208, 0.611434817314148, 0.6161341071128845, 0.6132561564445496, 0.6132282614707947, 0.6126169562339783, 0.6107966899871826, 0.6077389121055603, 0.6137898564338684, 0.6136023998260498, 0.6119069457054138, 0.6122148036956787, 0.6070537567138672, 0.6033900380134583, 0.6027915477752686, 0.6151486039161682, 0.6090421080589294, 0.612184464931488, 0.6131343245506287, 0.5996499061584473, 0.6072248220443726, 0.6312582492828369, 0.5941668152809143, 0.5942522287368774, 0.597930371761322, 0.5962151885032654, 0.6068524122238159, 0.6097219586372375, 0.5911586880683899, 0.5905605554580688, 0.5986447930335999, 0.588474690914154, 0.5944801568984985, 0.5975335240364075, 0.5882472395896912, 0.5789531469345093, 0.5973128080368042, 0.5926176905632019, 0.586629331111908, 0.5909105539321899, 0.5957790613174438, 0.6005371809005737, 0.5796265602111816, 0.5809245109558105, 0.5911422371864319, 0.5822663903236389, 0.5833029747009277], 'val_accuracy': [0.44155845046043396, 0.6233766078948975, 0.6038960814476013, 0.5974025726318359, 0.6233766078948975, 0.6363636255264282, 0.6168830990791321, 0.6363636255264282, 0.6363636255264282, 0.6428571343421936, 0.5584415793418884, 0.6363636255264282, 0.6103895902633667, 0.649350643157959, 0.6428571343421936, 0.6363636255264282, 0.6363636255264282, 0.6558441519737244, 0.6818181872367859, 0.6558441519737244, 0.6948052048683167, 0.6688311696052551, 0.6363636255264282, 0.6103895902633667, 0.6623376607894897, 0.6363636255264282, 0.6558441519737244, 0.6623376607894897, 0.649350643157959, 0.6233766078948975, 0.649350643157959, 0.6363636255264282, 0.6818181872367859, 0.649350643157959, 0.6753246784210205, 0.6688311696052551, 0.6818181872367859, 0.6428571343421936, 0.6428571343421936, 0.649350643157959, 0.6688311696052551, 0.6688311696052551, 0.6558441519737244, 0.6363636255264282, 0.6558441519737244, 0.649350643157959, 0.6428571343421936, 0.649350643157959, 0.649350643157959, 0.649350643157959, 0.6428571343421936, 0.6428571343421936, 0.6688311696052551, 0.649350643157959, 0.6753246784210205, 0.6558441519737244, 0.6558441519737244, 0.6623376607894897, 0.6753246784210205, 0.649350643157959, 0.6818181872367859, 0.6688311696052551, 0.649350643157959, 0.6688311696052551, 0.6558441519737244, 0.6623376607894897, 0.6753246784210205, 0.6948052048683167, 0.649350643157959, 0.6558441519737244, 0.6623376607894897, 0.649350643157959, 0.6558441519737244, 0.6688311696052551, 0.649350643157959, 0.6883116960525513, 0.6883116960525513, 0.6818181872367859, 0.6623376607894897, 0.6623376607894897, 0.6948052048683167, 0.7077922224998474, 0.6948052048683167, 0.701298713684082, 0.6688311696052551, 0.6753246784210205, 0.6818181872367859, 0.6818181872367859, 0.701298713684082, 0.6753246784210205, 0.7077922224998474, 0.7077922224998474, 0.6948052048683167, 0.6883116960525513, 0.6558441519737244, 0.701298713684082, 0.701298713684082, 0.701298713684082, 0.7077922224998474, 0.6948052048683167]}\n"
     ]
    }
   ],
   "source": [
    "# 編譯模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 訓練模型   迭代100次、批處理大小為10,\n",
    "history = model.fit(data, label, epochs=100, batch_size=10,\n",
    "                    validation_split = 0.2,    # 劃分資料集的 20% 作為驗證集用\n",
    "                    verbose = 2)               # 印出為精簡模式\n",
    "print(\"history: \",history.history)             # 印出歷史紀錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7487\n",
      "\n",
      "Loss: 0.53, Accuracy: 74.87%\n",
      "Prediction Accuracy: 74.87%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型\n",
    "loss, accuracy = model.evaluate(data, label)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "# 數據預測\n",
    "probabilities = model.predict(data)\n",
    "# 將 probabilities 的輸出值透過np.round()做四捨五入\n",
    "predictions = [float(np.round(x)) for x in probabilities]\n",
    "# 計算預測結果跟真實結果的平均差距\n",
    "accuracy = np.mean(predictions == label)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Tensorflow2_GPU]",
   "language": "python",
   "name": "conda-env-Tensorflow2_GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
