{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape :  (768, 8)\n",
      "label.shape :  (768,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# 加載，預處理數據集\n",
    "dataset = np.loadtxt(\"./pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "data = dataset[:, 0:8]    # 資料集\n",
    "label = dataset[:, 8]     # 標籤\n",
    "\n",
    "print(\"data.shape : \", data.shape)   # 印出資料集的維度\n",
    "print(\"label.shape : \",label.shape)  # 印出標籤維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 14:11:51.665719: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-21 14:11:51.666072: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())  # 印出網路資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 14:11:54.882169: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-10-21 14:11:55.048905: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 2s - loss: 6.0577 - accuracy: 0.4088 - val_loss: 1.8539 - val_accuracy: 0.6169 - 2s/epoch - 38ms/step\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 14:11:57.126529: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 0s - loss: 1.5265 - accuracy: 0.5472 - val_loss: 1.1363 - val_accuracy: 0.5455 - 357ms/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 1.1151 - accuracy: 0.5847 - val_loss: 0.9622 - val_accuracy: 0.6039 - 354ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.9743 - accuracy: 0.6042 - val_loss: 0.9675 - val_accuracy: 0.5974 - 355ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.8835 - accuracy: 0.6156 - val_loss: 0.9284 - val_accuracy: 0.6169 - 355ms/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.8857 - accuracy: 0.6319 - val_loss: 0.7472 - val_accuracy: 0.6364 - 356ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.8024 - accuracy: 0.6401 - val_loss: 0.6693 - val_accuracy: 0.6753 - 356ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.7995 - accuracy: 0.6515 - val_loss: 0.8187 - val_accuracy: 0.6429 - 418ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.7532 - accuracy: 0.6596 - val_loss: 0.6669 - val_accuracy: 0.6753 - 387ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.7070 - accuracy: 0.6612 - val_loss: 0.6527 - val_accuracy: 0.6818 - 362ms/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.6955 - accuracy: 0.6645 - val_loss: 0.6682 - val_accuracy: 0.6753 - 359ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.6834 - accuracy: 0.6694 - val_loss: 0.6488 - val_accuracy: 0.6883 - 356ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 0s - loss: 0.6849 - accuracy: 0.6759 - val_loss: 0.6872 - val_accuracy: 0.6623 - 356ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.6747 - accuracy: 0.6743 - val_loss: 0.6433 - val_accuracy: 0.7013 - 359ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.6495 - accuracy: 0.6792 - val_loss: 0.7245 - val_accuracy: 0.6364 - 362ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.6907 - accuracy: 0.6661 - val_loss: 0.6503 - val_accuracy: 0.6688 - 358ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.6455 - accuracy: 0.6971 - val_loss: 0.6290 - val_accuracy: 0.7078 - 354ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.6352 - accuracy: 0.6824 - val_loss: 0.6263 - val_accuracy: 0.7208 - 358ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.6283 - accuracy: 0.6938 - val_loss: 0.6590 - val_accuracy: 0.6948 - 357ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.6306 - accuracy: 0.6987 - val_loss: 0.7070 - val_accuracy: 0.6429 - 356ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.6611 - accuracy: 0.6840 - val_loss: 0.6661 - val_accuracy: 0.6494 - 362ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.6109 - accuracy: 0.7036 - val_loss: 0.6108 - val_accuracy: 0.7208 - 355ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.6176 - accuracy: 0.7248 - val_loss: 0.6269 - val_accuracy: 0.7078 - 358ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.6001 - accuracy: 0.7134 - val_loss: 0.6512 - val_accuracy: 0.6753 - 357ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.6080 - accuracy: 0.7296 - val_loss: 0.6277 - val_accuracy: 0.7403 - 369ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.6027 - accuracy: 0.7248 - val_loss: 0.6923 - val_accuracy: 0.6688 - 373ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.5951 - accuracy: 0.7443 - val_loss: 0.6274 - val_accuracy: 0.6818 - 391ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.5821 - accuracy: 0.7345 - val_loss: 0.6227 - val_accuracy: 0.7143 - 375ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.5890 - accuracy: 0.7231 - val_loss: 0.6060 - val_accuracy: 0.7532 - 355ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.5923 - accuracy: 0.7248 - val_loss: 0.6522 - val_accuracy: 0.6623 - 357ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.5857 - accuracy: 0.7410 - val_loss: 0.6245 - val_accuracy: 0.7078 - 353ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 0s - loss: 0.5946 - accuracy: 0.7345 - val_loss: 0.6072 - val_accuracy: 0.7532 - 356ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 0s - loss: 0.5674 - accuracy: 0.7378 - val_loss: 0.6213 - val_accuracy: 0.7143 - 353ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.5606 - accuracy: 0.7313 - val_loss: 0.6110 - val_accuracy: 0.7143 - 354ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 0s - loss: 0.5688 - accuracy: 0.7362 - val_loss: 0.6935 - val_accuracy: 0.6818 - 370ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.5592 - accuracy: 0.7394 - val_loss: 0.6770 - val_accuracy: 0.7403 - 365ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 0s - loss: 0.5941 - accuracy: 0.7150 - val_loss: 0.6088 - val_accuracy: 0.7078 - 398ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 0s - loss: 0.5629 - accuracy: 0.7394 - val_loss: 0.6268 - val_accuracy: 0.7208 - 367ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 0s - loss: 0.5635 - accuracy: 0.7394 - val_loss: 0.6066 - val_accuracy: 0.7143 - 376ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 0s - loss: 0.5484 - accuracy: 0.7362 - val_loss: 0.6095 - val_accuracy: 0.7078 - 360ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 0s - loss: 0.5464 - accuracy: 0.7508 - val_loss: 0.6425 - val_accuracy: 0.6753 - 352ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 0s - loss: 0.5292 - accuracy: 0.7752 - val_loss: 0.6179 - val_accuracy: 0.7273 - 382ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 0s - loss: 0.5477 - accuracy: 0.7508 - val_loss: 0.6074 - val_accuracy: 0.7078 - 389ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 0s - loss: 0.5551 - accuracy: 0.7492 - val_loss: 0.6567 - val_accuracy: 0.6818 - 395ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 0s - loss: 0.5515 - accuracy: 0.7573 - val_loss: 0.6095 - val_accuracy: 0.7273 - 394ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 0s - loss: 0.5339 - accuracy: 0.7541 - val_loss: 0.6048 - val_accuracy: 0.7532 - 361ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "62/62 - 0s - loss: 0.5401 - accuracy: 0.7476 - val_loss: 0.6369 - val_accuracy: 0.7143 - 366ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "62/62 - 0s - loss: 0.5363 - accuracy: 0.7459 - val_loss: 0.5974 - val_accuracy: 0.7078 - 360ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "62/62 - 0s - loss: 0.5445 - accuracy: 0.7443 - val_loss: 0.6045 - val_accuracy: 0.7013 - 363ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "62/62 - 0s - loss: 0.5484 - accuracy: 0.7508 - val_loss: 0.5920 - val_accuracy: 0.7273 - 361ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "62/62 - 0s - loss: 0.5320 - accuracy: 0.7492 - val_loss: 0.6012 - val_accuracy: 0.7403 - 363ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "62/62 - 0s - loss: 0.5371 - accuracy: 0.7524 - val_loss: 0.5966 - val_accuracy: 0.7013 - 360ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "62/62 - 0s - loss: 0.5478 - accuracy: 0.7362 - val_loss: 0.5883 - val_accuracy: 0.7143 - 350ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "62/62 - 0s - loss: 0.5373 - accuracy: 0.7378 - val_loss: 0.5879 - val_accuracy: 0.7143 - 351ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "62/62 - 0s - loss: 0.5308 - accuracy: 0.7671 - val_loss: 0.5845 - val_accuracy: 0.7403 - 352ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "62/62 - 0s - loss: 0.5123 - accuracy: 0.7541 - val_loss: 0.5989 - val_accuracy: 0.7468 - 350ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "62/62 - 0s - loss: 0.5147 - accuracy: 0.7671 - val_loss: 0.5875 - val_accuracy: 0.7208 - 350ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "62/62 - 0s - loss: 0.5235 - accuracy: 0.7557 - val_loss: 0.6107 - val_accuracy: 0.7273 - 356ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "62/62 - 0s - loss: 0.5256 - accuracy: 0.7606 - val_loss: 0.5854 - val_accuracy: 0.7273 - 354ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "62/62 - 0s - loss: 0.5159 - accuracy: 0.7573 - val_loss: 0.6088 - val_accuracy: 0.7403 - 351ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "62/62 - 0s - loss: 0.5346 - accuracy: 0.7443 - val_loss: 0.5971 - val_accuracy: 0.7273 - 356ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "62/62 - 0s - loss: 0.5556 - accuracy: 0.7443 - val_loss: 0.6238 - val_accuracy: 0.7532 - 354ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "62/62 - 0s - loss: 0.5257 - accuracy: 0.7557 - val_loss: 0.5933 - val_accuracy: 0.7273 - 354ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "62/62 - 0s - loss: 0.5251 - accuracy: 0.7606 - val_loss: 0.5773 - val_accuracy: 0.7273 - 359ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "62/62 - 0s - loss: 0.5220 - accuracy: 0.7638 - val_loss: 0.5963 - val_accuracy: 0.6818 - 348ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "62/62 - 0s - loss: 0.5316 - accuracy: 0.7671 - val_loss: 0.5815 - val_accuracy: 0.7338 - 399ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "62/62 - 0s - loss: 0.5222 - accuracy: 0.7524 - val_loss: 0.5787 - val_accuracy: 0.7273 - 383ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "62/62 - 0s - loss: 0.5175 - accuracy: 0.7508 - val_loss: 0.6181 - val_accuracy: 0.7208 - 356ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "62/62 - 0s - loss: 0.5293 - accuracy: 0.7557 - val_loss: 0.6020 - val_accuracy: 0.7013 - 358ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "62/62 - 0s - loss: 0.5217 - accuracy: 0.7410 - val_loss: 0.5856 - val_accuracy: 0.6948 - 350ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "62/62 - 0s - loss: 0.5192 - accuracy: 0.7606 - val_loss: 0.5796 - val_accuracy: 0.7273 - 360ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "62/62 - 0s - loss: 0.4990 - accuracy: 0.7557 - val_loss: 0.6082 - val_accuracy: 0.7143 - 358ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "62/62 - 0s - loss: 0.5091 - accuracy: 0.7541 - val_loss: 0.5674 - val_accuracy: 0.7403 - 358ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "62/62 - 0s - loss: 0.5025 - accuracy: 0.7573 - val_loss: 0.6162 - val_accuracy: 0.7013 - 351ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "62/62 - 0s - loss: 0.5189 - accuracy: 0.7638 - val_loss: 0.6133 - val_accuracy: 0.7013 - 354ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "62/62 - 0s - loss: 0.5083 - accuracy: 0.7573 - val_loss: 0.5729 - val_accuracy: 0.7338 - 351ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "62/62 - 0s - loss: 0.5010 - accuracy: 0.7622 - val_loss: 0.5802 - val_accuracy: 0.7597 - 355ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "62/62 - 0s - loss: 0.5111 - accuracy: 0.7557 - val_loss: 0.5638 - val_accuracy: 0.7273 - 353ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "62/62 - 0s - loss: 0.5148 - accuracy: 0.7557 - val_loss: 0.5701 - val_accuracy: 0.7403 - 352ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "62/62 - 0s - loss: 0.4982 - accuracy: 0.7541 - val_loss: 0.5756 - val_accuracy: 0.7403 - 353ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "62/62 - 0s - loss: 0.4941 - accuracy: 0.7704 - val_loss: 0.6384 - val_accuracy: 0.7208 - 354ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "62/62 - 0s - loss: 0.5010 - accuracy: 0.7590 - val_loss: 0.5648 - val_accuracy: 0.7403 - 353ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "62/62 - 0s - loss: 0.5396 - accuracy: 0.7492 - val_loss: 0.6076 - val_accuracy: 0.7273 - 353ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "62/62 - 0s - loss: 0.4987 - accuracy: 0.7573 - val_loss: 0.5853 - val_accuracy: 0.7143 - 364ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "62/62 - 0s - loss: 0.4951 - accuracy: 0.7736 - val_loss: 0.5628 - val_accuracy: 0.7208 - 356ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "62/62 - 0s - loss: 0.4832 - accuracy: 0.7704 - val_loss: 0.5801 - val_accuracy: 0.7273 - 397ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "62/62 - 0s - loss: 0.5040 - accuracy: 0.7492 - val_loss: 0.5662 - val_accuracy: 0.7338 - 376ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "62/62 - 0s - loss: 0.4984 - accuracy: 0.7671 - val_loss: 0.5655 - val_accuracy: 0.7338 - 354ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "62/62 - 0s - loss: 0.4986 - accuracy: 0.7590 - val_loss: 0.5677 - val_accuracy: 0.7273 - 357ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "62/62 - 0s - loss: 0.5068 - accuracy: 0.7622 - val_loss: 0.6536 - val_accuracy: 0.6948 - 355ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "62/62 - 0s - loss: 0.5309 - accuracy: 0.7524 - val_loss: 0.6098 - val_accuracy: 0.7468 - 366ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "62/62 - 0s - loss: 0.5454 - accuracy: 0.7443 - val_loss: 0.5686 - val_accuracy: 0.7273 - 354ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "62/62 - 0s - loss: 0.5021 - accuracy: 0.7524 - val_loss: 0.6051 - val_accuracy: 0.7403 - 356ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "62/62 - 0s - loss: 0.4996 - accuracy: 0.7573 - val_loss: 0.5725 - val_accuracy: 0.7403 - 350ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "62/62 - 0s - loss: 0.4860 - accuracy: 0.7752 - val_loss: 0.5804 - val_accuracy: 0.7532 - 355ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "62/62 - 0s - loss: 0.4936 - accuracy: 0.7606 - val_loss: 0.5699 - val_accuracy: 0.7143 - 354ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "62/62 - 0s - loss: 0.4825 - accuracy: 0.7655 - val_loss: 0.5753 - val_accuracy: 0.7338 - 357ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "62/62 - 0s - loss: 0.5198 - accuracy: 0.7524 - val_loss: 0.5546 - val_accuracy: 0.7532 - 359ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "62/62 - 0s - loss: 0.4892 - accuracy: 0.7638 - val_loss: 0.5583 - val_accuracy: 0.7468 - 351ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "62/62 - 0s - loss: 0.5002 - accuracy: 0.7606 - val_loss: 0.5993 - val_accuracy: 0.7078 - 373ms/epoch - 6ms/step\n",
      "history:  {'loss': [6.05769157409668, 1.526524305343628, 1.1151149272918701, 0.974259078502655, 0.8835297226905823, 0.8857265114784241, 0.802410364151001, 0.7994509339332581, 0.7531632781028748, 0.7070306539535522, 0.6955245137214661, 0.68337082862854, 0.6849461197853088, 0.6746599674224854, 0.6495282053947449, 0.6907423138618469, 0.6455152630805969, 0.6352109909057617, 0.6282656192779541, 0.6305631399154663, 0.661102294921875, 0.6109099984169006, 0.6176411509513855, 0.6001007556915283, 0.6079815626144409, 0.6026808619499207, 0.5950813889503479, 0.5821413397789001, 0.5889718532562256, 0.5923011898994446, 0.5856852531433105, 0.5946483612060547, 0.5674480199813843, 0.5606045126914978, 0.5687791705131531, 0.5591613054275513, 0.5940518975257874, 0.5628572106361389, 0.5634511709213257, 0.5484047532081604, 0.5463873744010925, 0.529242753982544, 0.5477458238601685, 0.5551308393478394, 0.5515004992485046, 0.5339186191558838, 0.5401129722595215, 0.5363007187843323, 0.5444619655609131, 0.5484200119972229, 0.5319634079933167, 0.5370790362358093, 0.5478417873382568, 0.5373263955116272, 0.5307934880256653, 0.5123311877250671, 0.5147182941436768, 0.5235140323638916, 0.5256031155586243, 0.5159265398979187, 0.534608006477356, 0.5556381940841675, 0.5257021188735962, 0.5250704884529114, 0.5219672918319702, 0.531588613986969, 0.5222088694572449, 0.5175389051437378, 0.5293449759483337, 0.521683931350708, 0.519204318523407, 0.49898216128349304, 0.5091190338134766, 0.5025167465209961, 0.5189018845558167, 0.5083450078964233, 0.5009860992431641, 0.5110647082328796, 0.5147926807403564, 0.4982128441333771, 0.49407219886779785, 0.5010417103767395, 0.5395862460136414, 0.4986882507801056, 0.4950534403324127, 0.4832017719745636, 0.5039788484573364, 0.4984418451786041, 0.4986356198787689, 0.5068243741989136, 0.530884861946106, 0.545372486114502, 0.5020664930343628, 0.4995635747909546, 0.4860401749610901, 0.49362874031066895, 0.4825421869754791, 0.5197668075561523, 0.48923805356025696, 0.5002340078353882], 'accuracy': [0.4087947905063629, 0.5472313165664673, 0.5846905708312988, 0.6042345762252808, 0.6156352162361145, 0.6319218277931213, 0.6400651931762695, 0.6514658331871033, 0.6596091389656067, 0.6612378358840942, 0.6644951105117798, 0.6693811416625977, 0.6758958101272583, 0.6742671132087708, 0.6791531443595886, 0.6661238074302673, 0.697068452835083, 0.6824104189872742, 0.6938111186027527, 0.6986970901489258, 0.6840391159057617, 0.7035830616950989, 0.7247557044029236, 0.7133550643920898, 0.7296417355537415, 0.7247557044029236, 0.7442997097969055, 0.7345277070999146, 0.7231270670890808, 0.7247557044029236, 0.7410423755645752, 0.7345277070999146, 0.7377850413322449, 0.7312703728675842, 0.7361564040184021, 0.7394136786460876, 0.7149837613105774, 0.7394136786460876, 0.7394136786460876, 0.7361564040184021, 0.7508143782615662, 0.7752443552017212, 0.7508143782615662, 0.7491856813430786, 0.7573290467262268, 0.7540717124938965, 0.7475570440292358, 0.7459283471107483, 0.7442997097969055, 0.7508143782615662, 0.7491856813430786, 0.7524430155754089, 0.7361564040184021, 0.7377850413322449, 0.767100989818573, 0.7540717124938965, 0.767100989818573, 0.7557003498077393, 0.7605863213539124, 0.7573290467262268, 0.7442997097969055, 0.7442997097969055, 0.7557003498077393, 0.7605863213539124, 0.7638436555862427, 0.767100989818573, 0.7524430155754089, 0.7508143782615662, 0.7557003498077393, 0.7410423755645752, 0.7605863213539124, 0.7557003498077393, 0.7540717124938965, 0.7573290467262268, 0.7638436555862427, 0.7573290467262268, 0.7622150182723999, 0.7557003498077393, 0.7557003498077393, 0.7540717124938965, 0.7703583240509033, 0.7589576840400696, 0.7491856813430786, 0.7573290467262268, 0.7736156582832336, 0.7703583240509033, 0.7491856813430786, 0.767100989818573, 0.7589576840400696, 0.7622150182723999, 0.7524430155754089, 0.7442997097969055, 0.7524430155754089, 0.7573290467262268, 0.7752443552017212, 0.7605863213539124, 0.7654723525047302, 0.7524430155754089, 0.7638436555862427, 0.7605863213539124], 'val_loss': [1.853929042816162, 1.1362802982330322, 0.962152361869812, 0.9674793481826782, 0.9283815026283264, 0.7472169399261475, 0.6693154573440552, 0.8187330961227417, 0.6668835878372192, 0.6526505351066589, 0.6681731343269348, 0.6488114595413208, 0.6871541142463684, 0.6433103680610657, 0.7244607210159302, 0.6502675414085388, 0.6289585828781128, 0.6262606382369995, 0.6589644551277161, 0.706954836845398, 0.6661470532417297, 0.6108191609382629, 0.6268993616104126, 0.6512271761894226, 0.6277292370796204, 0.6923254132270813, 0.6274306178092957, 0.6226649880409241, 0.606027364730835, 0.652160108089447, 0.6245454549789429, 0.607245922088623, 0.6212589144706726, 0.6109731197357178, 0.693524181842804, 0.6770384311676025, 0.6087732315063477, 0.6268121004104614, 0.6066167950630188, 0.6095163226127625, 0.6424784064292908, 0.6179220080375671, 0.6073973178863525, 0.6566988825798035, 0.6095261573791504, 0.6048084497451782, 0.636871337890625, 0.5974330306053162, 0.6045176386833191, 0.5920348167419434, 0.6012443900108337, 0.5965558290481567, 0.5882906317710876, 0.5878599286079407, 0.5844764113426208, 0.5989052653312683, 0.5875454545021057, 0.6106794476509094, 0.5853733420372009, 0.6088173389434814, 0.597082257270813, 0.6238245368003845, 0.5933046936988831, 0.5772632360458374, 0.5963214039802551, 0.5814682841300964, 0.5787157416343689, 0.6180683374404907, 0.6019592881202698, 0.5856251120567322, 0.5795966982841492, 0.6081980466842651, 0.5673850178718567, 0.6161573529243469, 0.6132583022117615, 0.5729243159294128, 0.5802188515663147, 0.5637805461883545, 0.5700510144233704, 0.5755794644355774, 0.6384252309799194, 0.5648465752601624, 0.6076216101646423, 0.5853110551834106, 0.5627864599227905, 0.5801125168800354, 0.5662307143211365, 0.565464198589325, 0.5677045583724976, 0.6535518765449524, 0.6097874641418457, 0.5685892701148987, 0.6051197648048401, 0.5725452899932861, 0.5804328322410583, 0.5698819756507874, 0.5752900838851929, 0.5545825958251953, 0.5583031177520752, 0.5992678999900818], 'val_accuracy': [0.6168830990791321, 0.5454545617103577, 0.6038960814476013, 0.5974025726318359, 0.6168830990791321, 0.6363636255264282, 0.6753246784210205, 0.6428571343421936, 0.6753246784210205, 0.6818181872367859, 0.6753246784210205, 0.6883116960525513, 0.6623376607894897, 0.701298713684082, 0.6363636255264282, 0.6688311696052551, 0.7077922224998474, 0.7207792401313782, 0.6948052048683167, 0.6428571343421936, 0.649350643157959, 0.7207792401313782, 0.7077922224998474, 0.6753246784210205, 0.7402597665786743, 0.6688311696052551, 0.6818181872367859, 0.7142857313156128, 0.7532467246055603, 0.6623376607894897, 0.7077922224998474, 0.7532467246055603, 0.7142857313156128, 0.7142857313156128, 0.6818181872367859, 0.7402597665786743, 0.7077922224998474, 0.7207792401313782, 0.7142857313156128, 0.7077922224998474, 0.6753246784210205, 0.7272727489471436, 0.7077922224998474, 0.6818181872367859, 0.7272727489471436, 0.7532467246055603, 0.7142857313156128, 0.7077922224998474, 0.701298713684082, 0.7272727489471436, 0.7402597665786743, 0.701298713684082, 0.7142857313156128, 0.7142857313156128, 0.7402597665786743, 0.7467532753944397, 0.7207792401313782, 0.7272727489471436, 0.7272727489471436, 0.7402597665786743, 0.7272727489471436, 0.7532467246055603, 0.7272727489471436, 0.7272727489471436, 0.6818181872367859, 0.7337662577629089, 0.7272727489471436, 0.7207792401313782, 0.701298713684082, 0.6948052048683167, 0.7272727489471436, 0.7142857313156128, 0.7402597665786743, 0.701298713684082, 0.701298713684082, 0.7337662577629089, 0.7597402334213257, 0.7272727489471436, 0.7402597665786743, 0.7402597665786743, 0.7207792401313782, 0.7402597665786743, 0.7272727489471436, 0.7142857313156128, 0.7207792401313782, 0.7272727489471436, 0.7337662577629089, 0.7337662577629089, 0.7272727489471436, 0.6948052048683167, 0.7467532753944397, 0.7272727489471436, 0.7402597665786743, 0.7402597665786743, 0.7532467246055603, 0.7142857313156128, 0.7337662577629089, 0.7532467246055603, 0.7467532753944397, 0.7077922224998474]}\n"
     ]
    }
   ],
   "source": [
    "# 編譯模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 訓練模型   迭代100次、批處理大小為10,\n",
    "history = model.fit(data, label, epochs=100, batch_size=10,\n",
    "                    validation_split = 0.2,    # 劃分資料集的 20% 作為驗證集用\n",
    "                    verbose = 2)               # 印出為精簡模式\n",
    "print(\"history: \",history.history)             # 印出歷史紀錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7487\n",
      "\n",
      "Loss: 0.53, Accuracy: 74.87%\n",
      "Prediction Accuracy: 74.87%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型\n",
    "loss, accuracy = model.evaluate(data, label)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "# 數據預測\n",
    "probabilities = model.predict(data)\n",
    "# 將 probabilities 的輸出值透過np.round()做四捨五入\n",
    "predictions = [float(np.round(x)) for x in probabilities]\n",
    "# 計算預測結果跟真實結果的平均差距\n",
    "accuracy = np.mean(predictions == label)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pai] *",
   "language": "python",
   "name": "conda-env-pai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
